# Documenta√ß√£o de Rotinas de ETL e An√°lise de Dados

## üìñ Vis√£o Geral do Projeto

Este reposit√≥rio documenta um projeto completo de pipeline de dados, demonstrando um fluxo de trabalho de ponta a ponta: desde a gera√ß√£o de dados brutos e a execu√ß√£o de testes de qualidade, passando por um processo de ETL com m√∫ltiplas etapas de tratamento e aplica√ß√£o de regras de neg√≥cio, at√© a visualiza√ß√£o final em um dashboard interativo no Power BI.

O objetivo √© apresentar uma solu√ß√£o robusta para o tratamento de dados, garantindo que as informa√ß√µes que chegam para a an√°lise final sejam √≠ntegras, consistentes e precisas.

---

## ‚ú® Principais Funcionalidades

* **Simula√ß√£o de Ambiente Real:** Gera√ß√£o de um dataset inicial com problemas comuns de qualidade de dados (nulos, duplicatas, valores negativos, etc.).
* **Testes de Qualidade de Dados:** Aplica√ß√£o de rotinas para verifica√ß√£o de **Integridade**, **Consist√™ncia** e **Precis√£o** dos dados.
* **Pipeline de ETL Sequencial:** Utiliza√ß√£o de Jobs (Notebooks Python) para transformar e enriquecer os dados passo a passo.
* **Armazenamento e Verifica√ß√£o:** Conex√£o com um banco de dados **SQLite** para armazenar e validar os dados processados.
* **Visualiza√ß√£o de Dados:** Desenvolvimento de um relat√≥rio no **Power BI** com KPIs e dashboards para an√°lise e suporte √† tomada de decis√£o.

---

## üìÇ Estrutura do Projeto e Arquivos

O fluxo de trabalho √© dividido nos seguintes componentes principais:

### 1. Processos ETL e Cria√ß√£o de Jobs (Notebooks Python)

> O cora√ß√£o do projeto, onde os dados s√£o gerados, testados, limpos e enriquecidos atrav√©s de uma s√©rie de rotinas sequenciais.

* `ETL1.ipynb`
    * **Descri√ß√£o:** Ponto de partida do pipeline. Este notebook gera um arquivo `.csv` simulando dados brutos com diversos problemas (campos nulos, valores negativos, produtos duplicados, etc.).
    * **Destaque:** Ao final, executa e apresenta relat√≥rios dos **Testes de Integridade, Consist√™ncia e Precis√£o**, fornecendo um diagn√≥stico completo da qualidade dos dados iniciais.

* `job_v1.ipynb`
    * **Descri√ß√£o:** Inicia o pipeline de tratamento. Este job estabelece uma conex√£o com um banco de dados **SQLite**, cria a estrutura de tabelas e armazena as informa√ß√µes do arquivo CSV gerado pelo `ETL1.ipynb` para verifica√ß√£o e processamento inicial.

* `job_v2.ipynb`
    * **Descri√ß√£o:** Aplica a primeira regra de neg√≥cio, que consiste em carregar para a pr√≥xima etapa apenas os registros que possuem uma **quantidade produzida superior a 10**.

* `job_v3.ipynb`
    * **Descri√ß√£o:** Aplica uma regra de limpeza de dados, removendo o caractere de **ponto final** (`.`) em colunas num√©ricas para evitar erros de truncamento.

* `job_v4.ipynb`
    * **Descri√ß√£o:** Executa uma etapa de **enriquecimento de dados**, onde novas colunas calculadas (como margem de lucro, por exemplo) s√£o adicionadas ao dataset para agregar valor √† an√°lise.

* `job_v5.1.ipynb`
    * **Descri√ß√£o:** Realiza um ciclo final de limpeza e tratamento nos dados j√° enriquecidos, garantindo a m√°xima qualidade e consist√™ncia do dataset antes de ser disponibilizado para a camada de visualiza√ß√£o.

### 2. Relat√≥rio em Power BI

* **Arquivo:** `Relatorio_Producao.pbix` (exemplo de nome)
    * **Descri√ß√£o:** Arquivo do Power BI contendo o relat√≥rio final. Nele, foram desenvolvidas f√≥rmulas em **DAX (Data Analysis Expressions)** para criar KPIs, m√©tricas e c√°lculos complexos que servem de base para os visuais.
    * **Destaque:** O resultado √© um dashboard interativo, projetado para atender √†s necessidades da audi√™ncia final e facilitar a tomada de decis√£o baseada em dados.

### 3. Documenta√ß√£o Adicional

* **Pasta:** `/Documentacao_SQL`
    * **Descri√ß√£o:** Cont√©m documentos e prints (`.png` ou `.jpg`) dos scripts SQL utilizados para interagir com o banco de dados, incluindo a cria√ß√£o de tabelas e outras consultas relevantes, servindo como um anexo t√©cnico do projeto.

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python
* **Bibliotecas:** Pandas, NumPy, Matplotlib, Seaborn, SQLite3
* **Banco de Dados:** SQLite
* **BI e Visualiza√ß√£o:** Microsoft Power BI
* **Linguagens de An√°lise:** DAX, SQL
